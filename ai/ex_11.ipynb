{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def count_codePoint(str):\n",
    "    counter = np.zeros(65535)\n",
    "    for i in range(len(str)):\n",
    "        code_point = ord(str[i])\n",
    "        if code_point > 65535 : continue\n",
    "        counter[code_point] += 1\n",
    "    counter = counter / len(str)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en' 'ja' 'ko']\n",
      "정답률 =  1.0\n"
     ]
    }
   ],
   "source": [
    "ko_str = '이것은 한국어 문장입니다.'\n",
    "ja_str = 'これは日本語の文章です。'\n",
    "en_str = 'This is English Sentensces'\n",
    "x_train = [count_codePoint(ko_str), count_codePoint(ja_str), count_codePoint(en_str)]\n",
    "y_train = ['ko', 'ja', 'en']\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "ko_test_str = '안녕하세요 반갑습니다.'\n",
    "ja_test_str = 'こんにちは'\n",
    "en_test_str = 'Hello'\n",
    "x_test = [count_codePoint(en_test_str), count_codePoint(ja_test_str), count_codePoint(ko_test_str)]\n",
    "y_test = ['en', 'ja', 'ko']\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print('정답률 = ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en' 'ja' 'ko']\n",
      "정답률 =  1.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "index = 0\n",
    "x_train = []\n",
    "y_train = []\n",
    "for file in glob.glob('./train/*.txt'):\n",
    "    y_train.append(file[8:10])\n",
    "    file_str = ''\n",
    "    for line in open(file, 'rt', encoding='UTF8'):\n",
    "        file_str = file_str + line\n",
    "    x_train.append(count_codePoint(file_str))\n",
    "y_prd = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print(\"정답률 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가다', 'Verb'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "malist = okt.pos(\"아버지 가방에 들어가신다.\", norm=True, stem= True)\n",
    "print(malist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이미지/Noun', 0.9988736510276794), ('대한/Noun', 0.9986572861671448), ('+/Punctuation', 0.9953462481498718), ('강사/Noun', 0.9934550523757935), ('아이템/Noun', 0.993233323097229), ('귀걸이/Noun', 0.9931872487068176), ('뷰/Noun', 0.9931594133377075), ('에스티/Noun', 0.9931522607803345), ('패션/Noun', 0.9929922819137573), ('의/Noun', 0.9927272200584412), ('에/Josa', 0.9927256107330322), ('·/Punctuation', 0.9926077127456665), (':/Punctuation', 0.9924814701080322), ('~!/Punctuation', 0.9924530982971191), ('나/Josa', 0.9924060702323914), ('첫/Noun', 0.9923668503761292), ('제/Modifier', 0.9922745823860168), ('`/Punctuation', 0.9921890497207642), ('콤마/Noun', 0.9919418096542358), ('재미/Noun', 0.9919390678405762)]\n",
      "[('?/Punctuation', 0.9998632669448853), ('도/Josa', 0.9998612999916077), ('!/Punctuation', 0.999835729598999), ('화/Noun', 0.9998306035995483), ('또/Noun', 0.9998301267623901), ('그렇다/Adjective', 0.9998259544372559), ('하고/Josa', 0.9998202323913574), ('부터/Josa', 0.9998180866241455), ('./Punctuation', 0.9998133778572083), ('과/Josa', 0.9998133182525635), ('보고/Noun', 0.9998131990432739), ('인데/Josa', 0.99981290102005), ('두/Determiner', 0.9998075366020203), ('요즘/Noun', 0.9998065829277039), ('있다/Adjective', 0.9998049736022949), ('그/Noun', 0.9998043775558472), ('없다/Adjective', 0.9998029470443726), ('임/Noun', 0.999802827835083), ('이/Determiner', 0.9998009204864502), ('로/Josa', 0.9998002052307129)]\n",
      "[('서현진/Noun', 0.9997478723526001), ('안재현/Noun', 0.9995197653770447), (\"'/Punctuation\", 0.9995129108428955), ('인사/Noun', 0.9994708895683289), ('이드/Noun', 0.9994615316390991), ('JTBC/Alpha', 0.9994481205940247), ('</Punctuation', 0.9994441866874695), ('속/Noun', 0.9994136691093445), ('의/Josa', 0.9994038939476013), ('의/Noun', 0.9993945360183716), ('엔/Josa', 0.999379575252533), ('에/Josa', 0.9993757009506226), ('월화드라마/Noun', 0.9993456602096558), ('6회/Number', 0.999238133430481), ('>/Punctuation', 0.9991888999938965), ('늘다/Verb', 0.9991081357002258), ('주연/Noun', 0.9990978837013245), ('여/Modifier', 0.9990484118461609), ('이다희/Noun', 0.9990478157997131), ('제/Modifier', 0.9989970326423645)]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data=[line.split('\\t') for line in f.read().splitlines()]\n",
    "        data=data[1:]\n",
    "    return data\n",
    "train_data = read_data('data/review.txt')\n",
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm = True, stem = True)]\n",
    "train_docs = [(tokenize(row[0])) for row in train_data]\n",
    "\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(train_docs)\n",
    "model.init_sims(replace=True)\n",
    "model.save('review.model')\n",
    "\n",
    "print(model.wv.most_similar(tokenize('스토리'),topn=20))\n",
    "print(model.wv.most_similar(tokenize('배우'),topn=20))\n",
    "print(model.wv.most_similar(tokenize('패션'),topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
