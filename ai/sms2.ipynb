{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_header='spam\\t'\n",
    "no_spam_header='ham\\t'\n",
    "documents=[]\n",
    "labels=[]\n",
    "with open('SMSSpamCollection1', encoding=\"utf-8\") as file_handle:\n",
    "    for line in file_handle: #파일을 한 줄씩 읽는다.\n",
    "        #startsWith() 메소드는 어떤 문자열이 특정 문자로 시작하는지 확인하여 결과를 true 혹은 false로 반환.\n",
    "        if line.startswith(spam_header): \n",
    "            labels.append(1) #레이블 값 입력\n",
    "            documents.append(line[len(spam_header):]) #각 줄에서 레이블 부분만 떼어내고 나머지를 documents에 넣는다.\n",
    "        elif line.startswith(no_spam_header):\n",
    "            labels.append(0)\n",
    "            documents.append(line[len(no_spam_header):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 777)\t1\n",
      "  (0, 301)\t1\n",
      "  (0, 812)\t1\n",
      "  (0, 304)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 170)\t1\n",
      "  (0, 551)\t1\n",
      "  (1, 792)\t1\n",
      "  (1, 384)\t1\n",
      "  (1, 509)\t1\n",
      "  (2, 59)\t1\n",
      "  (2, 573)\t1\n",
      "  (2, 739)\t1\n",
      "  (2, 668)\t1\n",
      "  (2, 568)\t1\n",
      "  (2, 583)\t1\n",
      "  (2, 696)\t1\n",
      "  (2, 255)\t1\n",
      "  (2, 795)\t1\n",
      "  (2, 152)\t1\n",
      "  (2, 802)\t1\n",
      "  (2, 237)\t2\n",
      "  (2, 266)\t1\n",
      "  (3, 226)\t1\n",
      "  (3, 610)\t2\n",
      "  :\t:\n",
      "  (5568, 304)\t1\n",
      "  (5569, 33)\t1\n",
      "  (5569, 10)\t1\n",
      "  (5569, 227)\t1\n",
      "  (5569, 454)\t1\n",
      "  (5569, 106)\t1\n",
      "  (5569, 159)\t1\n",
      "  (5569, 714)\t1\n",
      "  (5569, 731)\t1\n",
      "  (5569, 26)\t1\n",
      "  (5569, 483)\t1\n",
      "  (5569, 804)\t1\n",
      "  (5569, 137)\t1\n",
      "  (5569, 562)\t1\n",
      "  (5569, 573)\t1\n",
      "  (5570, 265)\t1\n",
      "  (5570, 296)\t1\n",
      "  (5570, 343)\t1\n",
      "  (5572, 310)\t1\n",
      "  (5572, 282)\t1\n",
      "  (5572, 195)\t1\n",
      "  (5572, 402)\t1\n",
      "  (5572, 783)\t1\n",
      "  (5572, 266)\t1\n",
      "  (5573, 733)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, stop_words=\"english\")\n",
    "term_counts = vectorizer.fit_transform(documents)\n",
    "print(term_counts)\n",
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer=TfidfTransformer(use_idf=False).fit(term_counts)\n",
    "features=tf_transformer.transform(term_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 70)\t0.3779644730092272\n",
      "  (0, 170)\t0.3779644730092272\n",
      "  (0, 301)\t0.3779644730092272\n",
      "  (0, 304)\t0.3779644730092272\n",
      "  (0, 551)\t0.3779644730092272\n",
      "  (0, 777)\t0.3779644730092272\n",
      "  (0, 812)\t0.3779644730092272\n",
      "  (1, 384)\t0.5773502691896258\n",
      "  (1, 509)\t0.5773502691896258\n",
      "  (1, 792)\t0.5773502691896258\n",
      "  (2, 59)\t0.25\n",
      "  (2, 152)\t0.25\n",
      "  (2, 237)\t0.5\n",
      "  (2, 255)\t0.25\n",
      "  (2, 266)\t0.25\n",
      "  (2, 568)\t0.25\n",
      "  (2, 573)\t0.25\n",
      "  (2, 583)\t0.25\n",
      "  (2, 668)\t0.25\n",
      "  (2, 696)\t0.25\n",
      "  (2, 739)\t0.25\n",
      "  (2, 795)\t0.25\n",
      "  (2, 802)\t0.25\n",
      "  (3, 223)\t0.4082482904638631\n",
      "  (3, 226)\t0.4082482904638631\n",
      "  :\t:\n",
      "  (5568, 756)\t0.2886751345948129\n",
      "  (5569, 10)\t0.2672612419124244\n",
      "  (5569, 26)\t0.2672612419124244\n",
      "  (5569, 33)\t0.2672612419124244\n",
      "  (5569, 106)\t0.2672612419124244\n",
      "  (5569, 137)\t0.2672612419124244\n",
      "  (5569, 159)\t0.2672612419124244\n",
      "  (5569, 227)\t0.2672612419124244\n",
      "  (5569, 454)\t0.2672612419124244\n",
      "  (5569, 483)\t0.2672612419124244\n",
      "  (5569, 562)\t0.2672612419124244\n",
      "  (5569, 573)\t0.2672612419124244\n",
      "  (5569, 714)\t0.2672612419124244\n",
      "  (5569, 731)\t0.2672612419124244\n",
      "  (5569, 804)\t0.2672612419124244\n",
      "  (5570, 265)\t0.5773502691896258\n",
      "  (5570, 296)\t0.5773502691896258\n",
      "  (5570, 343)\t0.5773502691896258\n",
      "  (5572, 195)\t0.4082482904638631\n",
      "  (5572, 266)\t0.4082482904638631\n",
      "  (5572, 282)\t0.4082482904638631\n",
      "  (5572, 310)\t0.4082482904638631\n",
      "  (5572, 402)\t0.4082482904638631\n",
      "  (5572, 783)\t0.4082482904638631\n",
      "  (5573, 733)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 70)\t0.3779644730092272\n",
      "  (0, 170)\t0.3779644730092272\n",
      "  (0, 301)\t0.3779644730092272\n",
      "  (0, 304)\t0.3779644730092272\n",
      "  (0, 551)\t0.3779644730092272\n",
      "  (0, 777)\t0.3779644730092272\n",
      "  (0, 812)\t0.3779644730092272\n",
      "  (1, 384)\t0.5773502691896258\n",
      "  (1, 509)\t0.5773502691896258\n",
      "  (1, 792)\t0.5773502691896258\n",
      "  (2, 59)\t0.25\n",
      "  (2, 152)\t0.25\n",
      "  (2, 237)\t0.5\n",
      "  (2, 255)\t0.25\n",
      "  (2, 266)\t0.25\n",
      "  (2, 568)\t0.25\n",
      "  (2, 573)\t0.25\n",
      "  (2, 583)\t0.25\n",
      "  (2, 668)\t0.25\n",
      "  (2, 696)\t0.25\n",
      "  (2, 739)\t0.25\n",
      "  (2, 795)\t0.25\n",
      "  (2, 802)\t0.25\n",
      "  (3, 223)\t0.4082482904638631\n",
      "  (3, 226)\t0.4082482904638631\n",
      "  :\t:\n",
      "  (5568, 756)\t0.2886751345948129\n",
      "  (5569, 10)\t0.2672612419124244\n",
      "  (5569, 26)\t0.2672612419124244\n",
      "  (5569, 33)\t0.2672612419124244\n",
      "  (5569, 106)\t0.2672612419124244\n",
      "  (5569, 137)\t0.2672612419124244\n",
      "  (5569, 159)\t0.2672612419124244\n",
      "  (5569, 227)\t0.2672612419124244\n",
      "  (5569, 454)\t0.2672612419124244\n",
      "  (5569, 483)\t0.2672612419124244\n",
      "  (5569, 562)\t0.2672612419124244\n",
      "  (5569, 573)\t0.2672612419124244\n",
      "  (5569, 714)\t0.2672612419124244\n",
      "  (5569, 731)\t0.2672612419124244\n",
      "  (5569, 804)\t0.2672612419124244\n",
      "  (5570, 265)\t0.5773502691896258\n",
      "  (5570, 296)\t0.5773502691896258\n",
      "  (5570, 343)\t0.5773502691896258\n",
      "  (5572, 195)\t0.4082482904638631\n",
      "  (5572, 266)\t0.4082482904638631\n",
      "  (5572, 282)\t0.4082482904638631\n",
      "  (5572, 310)\t0.4082482904638631\n",
      "  (5572, 402)\t0.4082482904638631\n",
      "  (5572, 783)\t0.4082482904638631\n",
      "  (5573, 733)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(features.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('3213LCW.pickle','wb') as file_handle:\n",
    "    pickle.dump((vocabulary, features, labels), file_handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
